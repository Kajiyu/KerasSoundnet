{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import glob\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import keras\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.layers import Input, BatchNormalization, Dropout, Conv2D, MaxPooling2D, ZeroPadding2D, Activation\n",
    "from keras.activations import relu \n",
    "from keras.models import Model as KModel\n",
    "import keras.backend as K\n",
    "from keras.losses import kullback_leibler_divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_name = '../model/sound8.npy'\n",
    "param_G = np.load(G_name, encoding='latin1').item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keras_conv_2d(prev_layer, in_ch, out_ch, k_h=1,\n",
    "                 k_w=1, d_h=1, d_w=1,p_h=0, p_w=0, pad='valid',\n",
    "                 name_scope='conv1', weight_dict=None, eps=1e-5, bn_act=True):\n",
    "    if pad=='valid':\n",
    "        padded_input = ZeroPadding2D((p_h, p_w))(prev_layer)\n",
    "    else:\n",
    "        padded_input = prev_layer\n",
    "    \n",
    "    if weight_dict is not None:\n",
    "        weights = weight_dict[name_scope]\n",
    "    \n",
    "    conv = Conv2D(out_ch, (k_h,k_w),\n",
    "               strides=(d_h, d_w))\n",
    "    # Need to pass input through so the layer knows its shape. \n",
    "    convOut = conv(padded_input)\n",
    "    if weight_dict is not None:\n",
    "        conv.set_weights([weights['weights'], weights['biases']])\n",
    "\n",
    "    # Break if we don't need to add activation or BatchNorm. \n",
    "    if not bn_act:\n",
    "        return convOut\n",
    "    \n",
    "    bn = BatchNormalization(epsilon=eps)\n",
    "    bnOut = bn(convOut)\n",
    "    \n",
    "    if weight_dict is not None:\n",
    "        bn.set_weights([weights[k] for k in ['gamma','beta','mean','var']])\n",
    "    act = Activation('relu')\n",
    "    rOut = act(bnOut)\n",
    "    \n",
    "    return rOut\n",
    "\n",
    "\n",
    "def keras_maxpool(prev, k_h=1, k_w=1, d_h=1, d_w=1):\n",
    "    return MaxPooling2D(pool_size=(k_h,k_w), strides=(d_h,d_w))(prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_sn_places_only(param_G=None, n_class=401):\n",
    "    inp = Input(shape=(None, 1, 1))\n",
    "    x1 = keras_conv_2d(inp, 1, 16, k_h=64, d_h=2, p_h=32, name_scope='conv1', weight_dict=param_G)\n",
    "    x2 = keras_maxpool(x1, k_h=8, d_h=8)\n",
    "    x3 = keras_conv_2d(x2, 16, 32, k_h=32, d_h=2, p_h=16, name_scope='conv2', weight_dict=param_G)\n",
    "    x4 = keras_maxpool(x3, k_h=8, d_h=8)\n",
    "    x5 = keras_conv_2d(x4, 32, 64, k_h=16, d_h=2, p_h=8, name_scope='conv3',weight_dict=param_G)\n",
    "    x6 = keras_conv_2d(x5, 64, 128, k_h=8, d_h=2, p_h=4, name_scope='conv4',weight_dict=param_G)\n",
    "    x7 = keras_conv_2d(x6, 128, 256, k_h=4, d_h=2, p_h=2, name_scope='conv5',weight_dict=param_G)\n",
    "    x8 = keras_maxpool(x7, k_h=4, d_h=4)\n",
    "    x9 = keras_conv_2d(x8, 256, 512, k_h=4, d_h=2, p_h=2, name_scope='conv6',weight_dict=param_G)\n",
    "    x = keras_conv_2d(x9, 512, 1024, k_h=4, d_h=2, p_h=2, name_scope='conv7',weight_dict=param_G)\n",
    "    if n_class == 401:\n",
    "        places = keras_conv_2d(x, 1024, n_class, k_h=8, d_h=2,name_scope='conv8_2',weight_dict=param_G,bn_act=False)\n",
    "    else:\n",
    "        places = keras_conv_2d(x, 1024, n_class, k_h=8, d_h=2,name_scope='conv8_2',bn_act=False)\n",
    "    places = Activation('softmax')(places)\n",
    "    placesModel = KModel(inputs=inp, outputs=places)\n",
    "    return placesModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = create_sn_places_only(param_G=param_G, n_class=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 1, 1)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, None, 1, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, None, 1, 16)       1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 1, 16)       64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, None, 1, 16)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, None, 1, 16)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, None, 1, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, None, 1, 32)       16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, 1, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, None, 1, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, None, 1, 32)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, None, 1, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, None, 1, 64)       32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, 1, 64)       256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, None, 1, 64)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, None, 1, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, None, 1, 128)      65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, None, 1, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, None, 1, 128)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, None, 1, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, None, 1, 256)      131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, None, 1, 256)      1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, None, 1, 256)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, None, 1, 256)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, None, 1, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, None, 1, 512)      524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, None, 1, 512)      2048      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, None, 1, 512)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, None, 1, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, None, 1, 1024)     2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, None, 1, 1024)     4096      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, None, 1, 1024)     0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, None, 1, 1024)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, None, 1, 365)      2990445   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, None, 1, 365)      0         \n",
      "=================================================================\n",
      "Total params: 5,868,829\n",
      "Trainable params: 5,864,765\n",
      "Non-trainable params: 4,064\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kld(p, q):\n",
    "    \"\"\"Calculates Kullbackâ€“Leibler divergence\"\"\"\n",
    "    print q.shape\n",
    "    p = p\n",
    "    q = q\n",
    "    q = np.mean(q, axis=1)\n",
    "    q = np.reshape(q, (1, q.shape[0], 1, q.shape[-1]))\n",
    "    print p.shape, q.shape\n",
    "    return np.sum(p * np.log(p / q), axis=(p.ndim - 1))\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.exp(x).sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, sr = librosa.load(\"./test_data/rank_1.mp3\")\n",
    "x = np.reshape(x, (1, x.shape[0], 1, 1))\n",
    "y_pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_true_sample = np.random.rand(365)\n",
    "y_true_sample = softmax(np.reshape(y_true_sample, (1, 1, 1, 365)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.17936718  0.17936718  0.17936718  0.0659855   0.0659855   0.0659855\n",
      "     0.0659855   0.0659855   0.0659855   0.0659855 ]]]]\n",
      "[[[[ 0.0659855   0.17936718  0.17936718  0.17936718  0.0659855   0.0659855\n",
      "     0.0659855   0.0659855   0.0659855   0.0659855 ]]]]\n",
      "(1, 1, 1, 10)\n",
      "(1, 1, 1, 10) (1, 1, 1, 10)\n",
      "[[[ 0.11338168]]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 1, 1, 0, 0,0,0,0,0,0])\n",
    "a = softmax(np.reshape(a, (1, 1, 1, a.shape[0])) + K.epsilon())\n",
    "b = np.array([0, 1, 1, 1, 0,0,0,0,0,0])\n",
    "b = softmax(np.reshape(b, (1, 1, 1, b.shape[0]))+ K.epsilon())\n",
    "print a\n",
    "print b\n",
    "d = kld(a,  b)\n",
    "print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0425030439048\n",
      "0.0422714633533\n",
      "0.0422885770774\n",
      "0.0422996535501\n",
      "0.0422878140762\n",
      "0.0422977245349\n",
      "0.0422968018702\n",
      "0.0422992727587\n",
      "0.0422799736301\n",
      "0.042299607573\n",
      "0.0422915991529\n",
      "0.0422910618671\n",
      "0.042303640829\n",
      "0.0422901042019\n",
      "0.0422917335082\n",
      "0.0422814482037\n",
      "0.0422826121768\n",
      "0.0422910264096\n",
      "0.0422859851033\n",
      "0.0422850708369\n",
      "0.0422844375668\n",
      "0.0422732628041\n",
      "0.0422938269409\n",
      "0.0422964009542\n",
      "0.0423403709286\n"
     ]
    }
   ],
   "source": [
    "for i in range(y_pred.shape[1]):\n",
    "    p = y_pred[0,i,0]\n",
    "    q = softmax(y_true_sample[0,0,0])\n",
    "    d = kld(p, q)\n",
    "    print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "epoch_size = 2000\n",
    "sample_per_epoch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_kld(y_true, y_pred):\n",
    "    y_true = K.clip(y_true, K.epsilon(), 1)\n",
    "    y_pred = K.mean(K.clip(y_pred, K.epsilon(), 1), axis=1)\n",
    "    return K.sum(y_true * K.log(y_true / y_pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "sample larger than population",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-ba8eee5673d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmovie_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/YumaKajihara/.pyenv/versions/anaconda2-2.5.0/lib/python2.7/random.pyc\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sample larger than population\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0mrandom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0m_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: sample larger than population"
     ]
    }
   ],
   "source": [
    "movie_list = []\n",
    "model.compile(loss=custom_kullback_leibler_divergence, optimizer='adam')\n",
    "for i in range(epoch_size):\n",
    "    pbar = tqdm(total=sample_per_epoch)\n",
    "    loss_val = 0\n",
    "    for j in range(sample_per_epoch):\n",
    "        movie_batch = random.sample(movie_list, batch_size)\n",
    "        x =[]\n",
    "        y_true = []\n",
    "        tmp_loss_val = model.train_on_batch(x, y_true)\n",
    "        print tmp_loss_val\n",
    "        break\n",
    "        pbar.update(1)\n",
    "        loss_val = loss_val + tmp_loss_val\n",
    "    pbar.close()\n",
    "    break\n",
    "    print str(i) +\"Epoch Mean Loss :\", loss_val / float(sample_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 1, 365) for Tensor u'activation_8_target_31:0', which has shape '(?, ?, ?, ?)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-cd530a4acdab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_true_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m365\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_true_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m365\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtmp_loss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtmp_loss_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/YumaKajihara/.pyenv/versions/anaconda2-2.5.0/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1640\u001b[0m                              'argument.')\n\u001b[1;32m   1641\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m         x, y, sample_weights = self._standardize_user_data(\n\u001b[0m\u001b[1;32m   1643\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/YumaKajihara/.pyenv/versions/anaconda2-2.5.0/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m                                           np.expand_dims(sparse_coo.col, 1)), 1)\n\u001b[1;32m   2268\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n",
      "\u001b[0;32m/Users/YumaKajihara/.pyenv/versions/anaconda2-2.5.0/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/YumaKajihara/.pyenv/versions/anaconda2-2.5.0/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    973\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    976\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1, 1, 365) for Tensor u'activation_8_target_31:0', which has shape '(?, ?, ?, ?)'"
     ]
    }
   ],
   "source": [
    "model.compile(loss=custom_kld, optimizer='adam')\n",
    "x, sr = librosa.load(\"./test_data/rank_1.mp3\")\n",
    "x = np.reshape(x, (1, x.shape[0], 1, 1))\n",
    "y_true_sample = np.random.rand(365)\n",
    "y_true_sample = softmax(np.reshape(y_true_sample, (1, 1, 1, 365)))\n",
    "tmp_loss_val = model.train_on_batch(x, y_true_sample)\n",
    "print tmp_loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
